
# sensitivity analysis - do the priors have too much influence

library(tidyverse)
library(brms)
library(tidybayes)
library(janitor)

#model 
exp_brm_gaus <- brm(value ~ name,
                    family = gaussian(),
                    data = data_exp,
                    prior = c(prior(normal(0,2), class = "b"),
                              prior(normal(0,2), class = "Intercept")),
                    chains = 1, iter = 1000,
                    file_refit = "on_change",
                    file = "applied_bayesian_modeling/models/exp_brm_gaus.rds")

plot(conditional_effects(exp_brm_gaus), points=T)

# sensitivity analysis
exp_brm_gaus_sens <- brm(value ~ name,
                    family = gaussian(),
                    data = data_exp,
                    prior = c(prior(normal(0,4), class = "b"),     #double the SD
                              prior(normal(0,4), class = "Intercept")),     #double the SD
                    chains = 1, iter = 1000,
                    file_refit = "on_change",
                    file = "applied_bayesian_modeling/models/exp_brm_gaus_sens.rds")

plot(conditional_effects(exp_brm_gaus_sens), points = T)

# you can do direct comparisons, but you can also just do a visual comparison to see if
# your priors are too tight. If the predictions don't match the raw data, the model is 
# "sensitive". Or, if your priors are correct but the model is still sensitive, you can
# justify why the priors are the way that they are.

# In a paper/presentation include the two plots above with one labeled as model and the other
# labeled as "wider priors" and that's it

# The more data you have, the less important the prior becomes anyways

# Performed a sensitivity analysis by re running the model with wider/less-informative priors
